{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f009edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import intake\n",
    "import xarray as xr\n",
    "\n",
    "from makecatalog_utils import src_header\n",
    "from makecatalog_utils import src_footer\n",
    "\n",
    "#from bs4 import BeautifulSoup\n",
    "#import codecs\n",
    "#import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df11213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56219b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_catalog(file_path_name, dataset_sub_name, parent_page, top_dir,tags, concat):\n",
    "    \"\"\"\n",
    "    FILE_NAME: If there are more than one file, FILE_NAME is the pattern for the NetCDF files, otherwise, Name of the NetCDF file. e.g.: 'air.mon.mean.nc' \n",
    "\n",
    "    DATASET_SUB_NAME: Name of the directory containing the NetCDf data files, e.g.: 'GHCN_CAMS'. If there is subdirectory like monthly, daily, etc., it should also be included and separated by \"_\".\n",
    "\n",
    "    PARENT_PAGE: Name of the parent directory in the dataset type hierarchy, e.g.: Temperature\n",
    "\n",
    "    TAG: A dataset may need to be catalogued into multiple child catalogs, e.g.: \"Atmosphere\", \"Temperature\". Please keep the format consistent\n",
    "    \"\"\"\n",
    "    file_path_name = file_path_name.strip('\"\"')\n",
    "    path, fileName = os.path.split(file_path_name)\n",
    "#    print(\"1 :\"+ file_path_name)\n",
    "#    print(\"2 :\"+ dataset_sub_name)\n",
    "#    print(\"3 :\"+ parent_page)\n",
    "#    print(\"4 :\"+ tags)\n",
    "    nfiles = len(glob.glob(file_path_name))\n",
    "    \n",
    "    # Set is_combine based on number of files\n",
    "    if (nfiles > 1):\n",
    "        is_combine= True\n",
    "    else:\n",
    "        is_combine= False\n",
    "\n",
    "    temp = dataset_sub_name\n",
    "\n",
    "    if int(is_combine) == True:\n",
    "        # Read with xarray\n",
    "        source = xr.open_mfdataset(file_path_name,combine='nested',concat_dim=concat)\n",
    "        src = source\n",
    "        # Use intake with xarray kwargs\n",
    "        source = intake.open_netcdf(file_path_name,concat_dim=concat,xarray_kwargs={'combine':'nested','decode_times':True})\n",
    "    else:\n",
    "        source = intake.open_netcdf(file_path_name)\n",
    "        src = xr.open_dataset(file_path_name)\n",
    "        source.discover()\n",
    "        \n",
    "    yamlPath='../intake-catalogs/'+top_dir+'/'+parent_page+'/'\n",
    "    if (not os.path.isdir(yamlPath)):\n",
    "        os.makedirs(yamlPath)\n",
    "        \n",
    "    yamlFile=dataset_sub_name.strip('\"\"')\n",
    "    dataset_sub_name = open(yamlPath+'/'+yamlFile+ '.yaml', 'w')\n",
    "    dataset_sub_name.write(source.yaml())\n",
    "    dataset_sub_name.close()\n",
    "    \n",
    "    print('YAML FILE CREATED: '+ yamlPath+'/'+yamlFile)\n",
    "    \n",
    "    #############################################\n",
    "\n",
    "    # CATALOG_DIR: Github repository containing the master catalog\n",
    "    # NOTE: It will be more accurate later\n",
    "    #catalog_dir = \"https://raw.githubusercontent.com/ou-esplab/SoM-ESPLab-DATASETS-CATALOG/main/intake-catalogs/\"\n",
    "    catalog_dir='.'        \n",
    "    open_catalog = catalog_dir + '/'+temp +\".yaml\"\n",
    "\n",
    "    # Look for attributes in the data\n",
    "    try:\n",
    "        title = src.attrs['title'] \n",
    "    except:\n",
    "        title = dataset_sub_name\n",
    "    try:\n",
    "        url = src.attrs['References']\n",
    "    except:\n",
    "        url =\"\"\n",
    "        \n",
    "    # Here url roles as the location\n",
    "    url = path\n",
    "    tags =tags.split(',')\n",
    "    \n",
    "    # Make HTML src code\n",
    "    html_repr =xr.core.formatting_html.dataset_repr(src).replace('\\\\n', '\\n')\n",
    "    _header = src_header(title, parent_page, open_catalog, url, tags, open_catalog)\n",
    "    _footer = src_footer()\n",
    "    html_src = _header + html_repr + _footer\n",
    "    \n",
    "    # Write HTML src code a file\n",
    "    \n",
    "    htmlPath='../'+top_dir+'/'+parent_page+'/'\n",
    "    if (not os.path.isdir(htmlPath)):\n",
    "        os.makedirs(htmlPath)\n",
    "    #page_name = fileName.replace('*','').replace('..','.')\n",
    "    page_name=yamlFile\n",
    "    html_page = htmlPath+page_name +\".html\" \n",
    "    with open(html_page , \"w\") as file:\n",
    "        file.write(html_src)\n",
    "\n",
    "    print('HTML PAGE CREATED: ', html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=['/data/esplab/shared/reanalysis/era5/daily/z200/z.*.nc','ERA5-daily-z200','ERA5-daily','reanalysis','reanalysis,geopotential,daily,gridded','']\n",
    "l2=['/data/esplab/shared/reanalysis/era5/daily/z500/z.*.nc','ERA5-daily-z500','ERA5-daily','reanalysis','reanalysis,geopotential,daily,gridded','']\n",
    "l3=['/data/esplab/shared/reanalysis/era5/daily/z850/z.*.nc','ERA5-daily-z850','ERA5-daily','reanalysis','reanalysis,geopotentail,daily,gridded','']\n",
    "\n",
    "datasets=[l1,l2,l3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30767163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/esplab/shared/reanalysis/era5/daily/z200/z.*.nc ERA5-daily-z200 ERA5-daily reanalysis reanalysis,geopotential,daily,gridded \n",
      "YAML FILE CREATED: ../intake-catalogs/reanalysis/ERA5-daily//ERA5-daily-z200\n",
      "HTML PAGE CREATED:  ../reanalysis/ERA5-daily/ERA5-daily-z200.html\n",
      "/data/esplab/shared/reanalysis/era5/daily/z500/z.*.nc ERA5-daily-z500 ERA5-daily reanalysis reanalysis,geopotential,daily,gridded \n",
      "YAML FILE CREATED: ../intake-catalogs/reanalysis/ERA5-daily//ERA5-daily-z500\n",
      "HTML PAGE CREATED:  ../reanalysis/ERA5-daily/ERA5-daily-z500.html\n",
      "/data/esplab/shared/reanalysis/era5/daily/z850/z.*.nc ERA5-daily-z850 ERA5-daily reanalysis reanalysis,geopotentail,daily,gridded \n",
      "YAML FILE CREATED: ../intake-catalogs/reanalysis/ERA5-daily//ERA5-daily-z850\n",
      "HTML PAGE CREATED:  ../reanalysis/ERA5-daily/ERA5-daily-z850.html\n"
     ]
    }
   ],
   "source": [
    "for file,dataset,parent,topdir,tags,concat in datasets:\n",
    "    print(file,dataset,parent,topdir,tags,concat)\n",
    "    generate_catalog(file,dataset,parent,topdir,tags,concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b060bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (catalog-ing)",
   "language": "python",
   "name": "catalog-ing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
